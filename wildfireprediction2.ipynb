{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e31735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": /physical_device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(\": {}\".format(device.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fba4716",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 3-4: truncated \\UXXXXXXXX escape (1724049977.py, line 13)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mparser.add_argument('\"C:\\Users\\Admin\\Desktop\\home files\\PATHWAYS\\Wildfire Prediction Model\\archive (3)\"', type=str, default='\"C:\\Users\\Admin\\Desktop\\home files\\PATHWAYS\\Wildfire Prediction Model\\archive (3)\"',\u001b[39m\n                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m (unicode error) 'unicodeescape' codec can't decode bytes in position 3-4: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#2. Configuration and Data Path Setup\n",
    "# Configuration parameters\n",
    "IMAGE_SIZE = (224, 224)  # Reduced size for faster training\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "N_CLASSES = 2\n",
    "\n",
    "def get_dataset_path():\n",
    "    \"\"\"Get dataset path from command line argument or use default\"\"\"\n",
    "    try:\n",
    "        parser = argparse.ArgumentParser(description='Wildfire Detection Model')\n",
    "        parser.add_argument('--dataset_path', type=str, default=r'C:\\Users\\Admin\\Desktop\\home files\\PATHWAYS\\Wildfire Prediction Model\\archive (3)',\n",
    "                          help='Path to the wildfire dataset')\n",
    "        args, _ = parser.parse_known_args()\n",
    "        return args.dataset_path\n",
    "    except:\n",
    "        # Default path if no argument is provided\n",
    "        return r'C:\\Users\\Admin\\Desktop\\home files\\PATHWAYS\\Wildfire Prediction Model\\archive (3)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ac097",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = get_dataset_path()\n",
    "\n",
    "train_path = os.path.join(dataset_path, 'train')\n",
    "valid_path = os.path.join(dataset_path, 'validation')  \n",
    "test_path = os.path.join(dataset_path, 'test')\n",
    "\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "print(f\"Train path: {train_path}\")\n",
    "print(f\"Validation path: {valid_path}\")\n",
    "print(f\"Test path: {test_path}\")\n",
    "\n",
    "for path in [train_path, valid_path, test_path]:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"✓ {path} exists\")\n",
    "        classes = os.listdir(path)\n",
    "        print(f\"  Classes found: {classes}\")\n",
    "        for class_name in classes:\n",
    "            class_path = os.path.join(path, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                num_images = len([f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "                print(f\"  {class_name}: {num_images} images\")\n",
    "    else:\n",
    "        print(f\"✗ {path} does not exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLASS_NAMES = ['nowildfire', 'wildfire']\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    dtype='float32'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_test_datagen = ImageDataGenerator(rescale=1./255, dtype='float32')\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASS_NAMES,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_generator = valid_test_datagen.flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASS_NAMES,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = valid_test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASS_NAMES,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {valid_generator.samples}\")\n",
    "print(f\"Test samples: {test_generator.samples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefcd9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weight_decay = 1e-4  \n",
    "\n",
    "model = Sequential([\n",
    "    # First Convolutional Block\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', \n",
    "           input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n",
    "           kernel_regularizer=regularizers.l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "           kernel_regularizer=regularizers.l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "           kernel_regularizer=regularizers.l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "           kernel_regularizer=regularizers.l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Third Convolutional Block\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "           kernel_regularizer=regularizers.l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(N_CLASSES, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966783c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb6403",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "checkpointer = ModelCheckpoint('wildfire_model_best.h5', verbose=1, \n",
    "                              save_best_only=True, monitor='val_accuracy')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, \n",
    "                              restore_best_weights=True, verbose=1)\n",
    "optimizer = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy', 'AUC', 'Precision', 'Recall']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(f\"Class weights: {class_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9e1b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=[checkpointer, early_stopping],\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe31177",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8067fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_results = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"Test AUC: {test_results[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ef1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save('wildfire_detection_model_final.h5')\n",
    "print(\"Model saved as 'wildfire_detection_model_final.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8000416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_wildfire(image_path, model):\n",
    "    \"\"\"Predict if an image contains wildfire\"\"\"\n",
    "\n",
    "    img = load_img(image_path, target_size=IMAGE_SIZE)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "    \n",
    "    prediction = model.predict(img_array)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    confidence = prediction[0][class_idx]\n",
    "\n",
    "    class_name = CLASS_NAMES[class_idx]\n",
    "    return class_name, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "result, confidence = predict_wildfire('path_to_image.jpg', model)\n",
    "print(f\"Prediction: {result} (Confidence: {confidence:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
